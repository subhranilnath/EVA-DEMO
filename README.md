<img src="https://github.com/subhranilnath/screenshots/blob/main/ss/Presentation1.png" width="100%">

# EVA ‚Äì Enhanced Virtual Assistant üéôüß†

EVA is a Python-based voice assistant that blends conversational AI, task automation, and real-time interaction through a modern PyQt5 GUI.

## üöÄ What It Can Help With

- Conversational AI: Context-aware responses via GPT-powered models.
- Voice Interaction: Speech-to-text and text-to-speech integration.
- Image Generation: Text-to-image via Stable Diffusion (Hugging Face API).
- Web Automation: Google search, YouTube playback, and more.
- Modular Design: Clean separation of GUI and backend for scalability.

## ‚öôÔ∏è Tech Stack

- Frontend: PyQt5, QMovie, QStackedWidget  
- AI Models: Cohere, Groq, Hugging Face, edge-tts, mtranslate  
- Libraries: asyncio, pyttsx3, SpeechRecognition, BeautifulSoup, PIL, pywhatkit  
- APIs: Hugging Face, Groq, Cohere  
- **Watch the Demo :** [Linkedin](https://www.linkedin.com/posts/subhranil-nath_ai-python-voiceassistant-activity-7362444477891792896-JH46?utm_source=share&utm_medium=member_desktop&rcm=ACoAAF1ughAB6vTvwKeZUkgJhbHa3SOhg9uneRM) 

## üí° How to Use It

1. Clone the repository and create a virtual environment. Then install dependencies from requirements.txt.
2. Add your API keys in a .env file (Groq, Cohere, Hugging Face).
3. Run the main Python script: **Main.py** 
